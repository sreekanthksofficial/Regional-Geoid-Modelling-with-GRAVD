{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b4823-430f-475c-8c0b-c75aef06d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30446678-fa2c-4888-92ae-385ba5d2d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_GRAVD_gravity_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and prepare airborne gravity data from GRAV-D text file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the gravity data text file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Processed DataFrame with identifier, latitude, longitude, altitude, and gravity columns.\n",
    "    \"\"\"\n",
    "    # Extract file name from path and print it\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f\"Loading file: {file_name}\")\n",
    "\n",
    "    # Load the file, reading only the required columns (lat, long, altitude, gravity)\n",
    "    gravity_data = pd.read_csv(\n",
    "        file_path,\n",
    "        delim_whitespace=True,\n",
    "        usecols=[2, 3, 4, 5],\n",
    "        names=['Latitude(DD)', 'Longitude(DD)', 'Altitude(m)', 'Gravity(mGal)'],\n",
    "        header=None\n",
    "    )\n",
    "    \n",
    "    # Add identifier column\n",
    "    gravity_data['identifier'] = gravity_data.index\n",
    "\n",
    "    # Check for large data and ask about downsampling\n",
    "    num_rows = len(gravity_data)\n",
    "    print(f\"Number of points in dataset: {num_rows}\")\n",
    "\n",
    "    if num_rows > 200000:\n",
    "        response = input(\"Data has more than 200,000 points. Do you want to downsample? (y/n): \").strip().lower()\n",
    "        if response == 'y':\n",
    "            try:\n",
    "                interval_input = input(\"Enter downsampling interval (default is 10): \").strip()\n",
    "                interval = int(interval_input) if interval_input else 10\n",
    "                gravity_data = gravity_data.iloc[::interval].reset_index(drop=True)\n",
    "                print(f\"Data downsampled using interval {interval}. New number of rows: {len(gravity_data)}\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid interval input. Proceeding without downsampling.\")\n",
    "\n",
    "\n",
    "    # Reorder columns\n",
    "    gravity_data = gravity_data[['identifier', 'Latitude(DD)', 'Longitude(DD)', 'Altitude(m)', 'Gravity(mGal)']]\n",
    "\n",
    "    return gravity_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573efca7-6755-442b-9494-e82e0ee4aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_icgem_input_chunks(gravity_df, output_folder_path, chunk_size=10000):\n",
    "    \"\"\"\n",
    "    Splits the gravity DataFrame into chunks and saves each chunk to a text file.\n",
    "\n",
    "    Parameters:\n",
    "    gravity_df (pd.DataFrame): DataFrame containing 'identifier', 'Latitude(DD)', 'Longitude(DD)', and 'Altitude(m)'.\n",
    "    output_folder_path (str): Path to the folder where chunked text files will be saved.\n",
    "    chunk_size (int): Number of rows per file. Default is 10,000.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "    input_data = gravity_df[['identifier', 'Latitude(DD)', 'Longitude(DD)', 'Altitude(m)']]\n",
    "    num_chunks = (len(input_data) // chunk_size) + 1\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = start_idx + chunk_size\n",
    "        chunk = input_data[start_idx:end_idx]\n",
    "        output_file = os.path.join(output_folder_path, f\"IndexLatLongAlt_Part{i+1}.txt\")\n",
    "        chunk.to_csv(output_file, sep='\\t', index=False, header=False)\n",
    "        print(f\"Chunk {i+1} saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeaf6b8-360e-49d1-a624-2d245e3e0d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_icgem_output_chunks(folder_path):\n",
    "    \"\"\"\n",
    "    Loads and concatenates .dat files from the specified folder that match \n",
    "    the naming pattern 'GGM05G_Part*.dat'. Assumes files follow ICGEM format \n",
    "    with a header ending in 'end_of_head'.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): Path to the folder containing the .dat files.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Combined DataFrame with columns:\n",
    "        ['identifier', 'longitude', 'latitude', 'h_over_ell', 'geoid', 'gravity_anomaly']\n",
    "    \"\"\"\n",
    "    # Get a sorted list of relevant .dat files\n",
    "    file_list = sorted([\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if f.startswith(\"GGM05G_Part\") and f.endswith('.dat')\n",
    "    ])\n",
    "\n",
    "    dataframes = []\n",
    "\n",
    "    for filename in file_list:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Skip header lines until 'end_of_head'\n",
    "            for line in file:\n",
    "                if 'end_of_head' in line:\n",
    "                    break\n",
    "\n",
    "            # Read remaining lines into a DataFrame\n",
    "            df = pd.read_csv(file, delim_whitespace=True, header=None)\n",
    "\n",
    "            # Assign column names\n",
    "            df.columns = [\n",
    "                \"identifier\", \"longitude\", \"latitude\",\n",
    "                \"h_over_ell\", \"geoid\", \"gravity_anomaly\"\n",
    "            ]\n",
    "\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    icgem_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return icgem_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e09096-5c7c-4423-8ade-ac3b733e6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dem():\n",
    "    \"\"\"\n",
    "    Loads a DEM file, replaces nodata values with NaN, generates lat/lon grids,\n",
    "    and prints extent information.\n",
    "\n",
    "    Returns:\n",
    "    dem_array (np.ndarray): Processed DEM values.\n",
    "    lon_grid (np.ndarray): Longitude grid.\n",
    "    lat_grid (np.ndarray): Latitude grid.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ—ºï¸  Loading DEM for the Modeling Region\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nInstructions:\")\n",
    "    print(\"- Please provide the SRTM 1 Arc-Second DEM (.tif format) for your modeling region.\")\n",
    "    print(\"- Ensure the DEM is within the extent of your gravity data.\")\n",
    "    print(\"- This DEM should represent the topography for the entire block you're modeling.\")\n",
    "    print(\"- Commonly used extent sizes are 1Â° x 1Â° or 2Â° x 2Â° in decimal degrees.\")\n",
    "    print(\"- DEM spatial resolution should be 1 arc-second (~30 meters).\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    # Ask user for DEM file path\n",
    "    dem_path = input(\"Enter the full path to the DEM file: \").strip()\n",
    "\n",
    "    # Read DEM file\n",
    "    with rasterio.open(dem_path) as dem:\n",
    "        dem_array = dem.read(1).astype(float)\n",
    "        transform = dem.transform\n",
    "        bounds = dem.bounds\n",
    "        height, width = dem_array.shape\n",
    "        nodata_value = dem.nodata\n",
    "\n",
    "    # Replace nodata with NaN\n",
    "    dem_array[dem_array == nodata_value] = np.nan\n",
    "\n",
    "    # Generate longitude and latitude grids\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    lon_grid, lat_grid = rasterio.transform.xy(transform, rows, cols)\n",
    "    lon_grid = np.array(lon_grid)\n",
    "    lat_grid = np.array(lat_grid)\n",
    "\n",
    "    # Calculate region extent and directions\n",
    "    min_lat, max_lat = bounds.bottom, bounds.top\n",
    "    min_lon, max_lon = bounds.left, bounds.right\n",
    "\n",
    "    lat_dir = \"North\" if max_lat > 0 else \"South\"\n",
    "    lon_dir = \"East\" if max_lon > 0 else \"West\"\n",
    "\n",
    "    # Round for printing\n",
    "    min_lat_int = round(abs(min_lat))\n",
    "    max_lat_int = round(abs(max_lat))\n",
    "    min_lon_int = round(abs(min_lon))\n",
    "    max_lon_int = round(abs(max_lon))\n",
    "\n",
    "    # Calculate spatial extent\n",
    "    latitude_extent = round(abs(max_lat - min_lat), 4)\n",
    "    longitude_extent = round(abs(max_lon - min_lon), 4)\n",
    "\n",
    "    # For friendly display: if close to whole number, display as \"~1Â°\"\n",
    "    lat_disp = f\"~{round(latitude_extent)}Â°\" if abs(latitude_extent - round(latitude_extent)) < 0.01 else f\"{latitude_extent}Â°\"\n",
    "    lon_disp = f\"~{round(longitude_extent)}Â°\" if abs(longitude_extent - round(longitude_extent)) < 0.01 else f\"{longitude_extent}Â°\"\n",
    "\n",
    "    print(\"\\nðŸ“Œ  DEM Extent Information:\")\n",
    "    print(f\"- Latitude extent: {min_lat_int}Â° to {max_lat_int}Â° {lat_dir}\")\n",
    "    print(f\"- Longitude extent: {min_lon_int}Â° to {max_lon_int}Â° {lon_dir}\")\n",
    "    print(f\"\\nðŸ“  Your modeling region spans approximately {lat_disp} x {lon_disp}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "    return dem_array, lon_grid, lat_grid, latitude_extent, longitude_extent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffbf546-a57d-47a2-850a-ab825b8aba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inputs():\n",
    "    \"\"\"\n",
    "    Interactively loads GRAV-D data, ICGEM outputs, and DEM file, and prepares them for modeling.\n",
    "\n",
    "    Returns:\n",
    "    gravity_df (pd.DataFrame): GRAV-D airborne gravity data.\n",
    "    icgem_df (pd.DataFrame): ICGEM output data.\n",
    "    dem_array (np.ndarray): DEM values with nodata replaced as NaN.\n",
    "    lon_grid (np.ndarray): Longitude grid derived from DEM.\n",
    "    lat_grid (np.ndarray): Latitude grid derived from DEM.\n",
    "    \"\"\"\n",
    "    # Ask user for GRAV-D gravity file\n",
    "    gravity_file_path = input(\"Enter the full path to the GRAV-D gravity file: \").strip()\n",
    "    gravity_df = load_GRAVD_gravity_data(gravity_file_path)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ”  Preparing for ICGEM Input Creation\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nImportant Notes:\")\n",
    "    print(\"- To reduce gravity data, an approximate orthometric height of the flight is required.\")\n",
    "    print(\"- Use the GGM05G geoid model to estimate geoid undulation at the observation points.\")\n",
    "    print(\"- Visit the ICGEM website to download geoid undulation and gravity anomaly values at those points.\")\n",
    "    print(\"- Gravity anomaly data will be used in later stages (e.g., for remove-restore steps), so download it now.\")\n",
    "    print(\"- âš ï¸ ICGEM only allows up to 10,000 points per file upload.\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    \n",
    "    # Ask if ICGEM input chunks are already created\n",
    "    user_input = input(\"Have you already created the ICGEM input chunks? (yes/no): \").strip().lower()\n",
    "    if user_input == \"no\":\n",
    "        icgem_input_path = input(\"Enter the folder path where you want to save the ICGEM input chunks: \").strip()\n",
    "        write_icgem_input_chunks(gravity_df, icgem_input_path, chunk_size=10000)\n",
    "    else:\n",
    "        print(\"Skipping chunk creation.\")\n",
    "\n",
    "\n",
    "    # Notes before downloading and naming ICGEM output files\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“¥  Downloading ICGEM Outputs\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nInstructions:\")\n",
    "    print(\"- Now go to the ICGEM website and upload each of the ICGEM input chunks created earlier.\")\n",
    "    print(\"- For each chunk, download the required data: geoid undulation and gravity anomaly using the GGM05G model.\")\n",
    "    print(\"- Save each downloaded file with the following naming convention:\")\n",
    "    print(\"    ðŸ‘‰ GGM05G_Part01.txt, GGM05G_Part02.txt, ..., GGM05G_PartXX.txt\")\n",
    "    print(\"- Make sure the part numbers are zero-padded to two digits (e.g., 01, 02, ..., 10).\")\n",
    "    print(\"- This naming convention is necessary for automatic reading and merging of the output files.\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "    # Ask for ICGEM output path\n",
    "    icgem_output_path = input(\"Enter the folder path containing ICGEM output files: \").strip()\n",
    "    icgem_df = load_icgem_output_chunks(icgem_output_path)\n",
    "\n",
    "    # Loading DEM for modelling region and generating latitude and longitude grids\n",
    "    dem_array, lon_grid, lat_grid, latitude_extent, longitude_extent = load_dem()\n",
    "\n",
    "\n",
    "    return gravity_df, icgem_df, dem_array, lon_grid, lat_grid, latitude_extent, longitude_extent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d49ce-42c7-4d15-8bb6-c379fe4dd379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_point_wise_calculations(calculation_df):\n",
    "    \"\"\"\n",
    "    Perform point-wise gravity-related calculations on a given DataFrame.\n",
    "\n",
    "    This function computes a series of gravity-related quantities for each point\n",
    "    in the input DataFrame based on ellipsoidal constants of the WGS 84 reference system.\n",
    "    \n",
    "    Calculations include:\n",
    "        - Normal gravity based on Somigliana's formula\n",
    "        - Approximate orthometric height (H â‰ˆ h - N)\n",
    "        - Second-order free-air correction\n",
    "        - Free Air Anomaly (FAA)\n",
    "        - Long wavelength correction using GGM gravity anomaly\n",
    "        - Atmospheric correction for gravitational attraction\n",
    "        - Final surface gravity anomaly corrected for atmospheric effects\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    calculation_df : pandas.DataFrame\n",
    "        Input DataFrame must contain the following columns:\n",
    "        - 'Latitude(DD)'         : Latitude in decimal degrees\n",
    "        - 'Altitude(m)'          : Ellipsoidal height in meters\n",
    "        - 'Geoid_GGM(m)'         : Geoid undulation from GGM in meters\n",
    "        - 'Gravity(mGal)'        : Observed gravity in mGal\n",
    "        - 'Gravity_Anomaly_GGM(mGal)' : Gravity anomaly from GGM in mGal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    calculation_df : pandas.DataFrame\n",
    "        Updated DataFrame with the following additional columns:\n",
    "        - 'g_normal(mGal)'                   : Normal gravity\n",
    "        - 'H_approx(m)'                      : Approximate orthometric height\n",
    "        - 'Free_Air_Correction(mGal)'        : 2nd-order free air correction\n",
    "        - 'FAA(mGal)'                        : Free Air Anomaly\n",
    "        - 'gravity_anomaly_s_mw(mGal)'       : Short and medium wavelength gravity anomaly\n",
    "        - 'delta_atm(mGal)'                  : Atmospheric correction\n",
    "        - 'gravity_anomaly_s_mw_atm(mGal)'   : gravity anomaly after all corrections upto terrain correction\n",
    "    \"\"\"\n",
    "    # Ellipsoidal Constants (WGS 84)\n",
    "    omega = 7.292115e-5        # Angular velocity of Earth (rad/s)\n",
    "    a = 6378137.0              # Semi-major axis (meters)\n",
    "    b = 6356752.3142           # Semi-minor axis (meters)\n",
    "    GM = 3986004.418e8         # Geocentric gravitational constant (m^3/s^2)\n",
    "    f = 1 / 298.257223563      # Flattening\n",
    "    gamma_eq = 978032.53359    # Normal gravity at equator (mGal)\n",
    "    gamma_pole = 983218.49378  # Normal gravity at pole (mGal)\n",
    "\n",
    "    # Normal gravity calculation (Somigliana's formula)\n",
    "    lat_rad = np.radians(calculation_df['Latitude(DD)'])\n",
    "    cos_lat = np.cos(lat_rad)\n",
    "    sin_lat = np.sin(lat_rad)\n",
    "\n",
    "    numerator = (a * gamma_eq * cos_lat**2) + (b * gamma_pole * sin_lat**2)\n",
    "    denominator = np.sqrt((a**2 * cos_lat**2) + (b**2 * sin_lat**2))\n",
    "    calculation_df['g_normal(mGal)'] = numerator / denominator\n",
    "\n",
    "    # Approximate orthometric height, H = h - N\n",
    "    calculation_df['H_approx(m)'] = calculation_df['Altitude(m)'] - calculation_df['Geoid_GGM(m)']\n",
    "\n",
    "    # 2nd order free air correction\n",
    "    m = (omega**2 * a**2 * b) / GM\n",
    "    c1 = (-2 * calculation_df['g_normal(mGal)']) / a\n",
    "    term1 = (1 + f + m - 2 * f * sin_lat**2) * calculation_df['H_approx(m)']\n",
    "    c2 = 3 * (calculation_df['g_normal(mGal)'] / (a**2))\n",
    "    term2 = calculation_df['H_approx(m)']**2\n",
    "    fac = (c1 * term1) + (c2 * term2)\n",
    "    calculation_df['Free_Air_Correction(mGal)'] = -fac\n",
    "\n",
    "    # Free Air Anomaly (FAA)\n",
    "    calculation_df['FAA(mGal)'] = (\n",
    "        calculation_df['Gravity(mGal)'] \n",
    "        + calculation_df['Free_Air_Correction(mGal)'] \n",
    "        - calculation_df['g_normal(mGal)']\n",
    "    )\n",
    "\n",
    "    # Remove long wavelength effects\n",
    "    calculation_df['gravity_anomaly_s_mw(mGal)'] = (\n",
    "        calculation_df['FAA(mGal)'] - calculation_df['Gravity_Anomaly_GGM(mGal)']\n",
    "    )\n",
    "\n",
    "    # Atmospheric correction\n",
    "    H = calculation_df['H_approx(m)']\n",
    "    calculation_df['delta_atm(mGal)'] = (\n",
    "        0.871 \n",
    "        - 1.0298e-4 * H \n",
    "        + 5.3105e-9 * H**2\n",
    "        - 2.1642e-13 * H**3\n",
    "        + 9.5246e-18 * H**4\n",
    "        - 2.2411e-22 * H**5\n",
    "    )\n",
    "\n",
    "    calculation_df['gravity_anomaly_s_mw_atm(mGal)'] = (\n",
    "        calculation_df['gravity_anomaly_s_mw(mGal)'] - calculation_df['delta_atm(mGal)']\n",
    "    )\n",
    "\n",
    "    return calculation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18104a1f-d99c-4a06-bb62-7cc2d2ea0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataframe_column_map(df, value_col, \n",
    "                              lat_col='Latitude(DD)', lon_col='Longitude(DD)', \n",
    "                              title=None, cmap='jet', point_size=10, alpha=0.8, \n",
    "                              save_path=None, dpi=300, interactive=True):\n",
    "    \"\"\"\n",
    "    Plots any numeric value from a DataFrame over geographic coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing data\n",
    "    - value_col: str, name of the column to plot\n",
    "    - lat_col: str, name of the latitude column (default: 'Latitude(DD)')\n",
    "    - lon_col: str, name of the longitude column (default: 'Longitude(DD)')\n",
    "    - title: str, title of the plot (optional)\n",
    "    - cmap: str, matplotlib colormap name (default: 'jet')\n",
    "    - point_size: int, size of scatter points (default: 10)\n",
    "    - alpha: float, transparency of the points (default: 0.8)\n",
    "    - save_path: str or Path, path to save the figure (optional)\n",
    "    - dpi: int, resolution of saved figure (default: 300)\n",
    "    - interactive: bool, if True, ask user whether to save plot\n",
    "\n",
    "    Returns:\n",
    "    - fig, ax: Matplotlib figure and axis objects\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import cartopy.crs as ccrs\n",
    "    from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "    from matplotlib.ticker import MultipleLocator\n",
    "    import numpy as np\n",
    "\n",
    "    vmin = df[value_col].min()\n",
    "    vmax = df[value_col].max()\n",
    "    ticks = np.linspace(vmin, vmax, 10)\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "    sc = ax.scatter(\n",
    "        df[lon_col],\n",
    "        df[lat_col],\n",
    "        c=df[value_col],\n",
    "        cmap=cmap,\n",
    "        s=point_size,\n",
    "        alpha=alpha,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        transform=ccrs.PlateCarree()\n",
    "    )\n",
    "\n",
    "    # Gridlines\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {'size': 12}\n",
    "    gl.ylabel_style = {'size': 12}\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlocator = MultipleLocator(1)\n",
    "    gl.ylocator = MultipleLocator(1)\n",
    "\n",
    "    # Title and colorbar\n",
    "    if title is None:\n",
    "        title = f\"Map of {value_col}\"\n",
    "    plt.title(title, fontsize=14)\n",
    "\n",
    "    cbar = plt.colorbar(sc, ax=ax, orientation='vertical', label=value_col, shrink=0.7, ticks=ticks)\n",
    "\n",
    "    # Ask to save\n",
    "    if interactive and save_path is None:\n",
    "        save_choice = input(\"Do you want to save the plot as JPEG? (yes/no): \").strip().lower()\n",
    "        if save_choice == \"yes\":\n",
    "            save_path = input(\"Enter full path (including filename.jpeg) to save the JPEG: \").strip()\n",
    "    \n",
    "    if save_path:\n",
    "        if not save_path.lower().endswith(\".jpeg\"):\n",
    "            save_path += \".jpeg\"\n",
    "        plt.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
    "        print(f\"âœ… Plot saved to: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0338ec-04ea-4f87-8966-4139ef299ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "def plot_2d_array_on_map(\n",
    "    data_array, \n",
    "    lat_grid, \n",
    "    lon_grid, \n",
    "    title, \n",
    "    cmap='jet', \n",
    "    unit_label='Value', \n",
    "    save_fig=False, \n",
    "    filename=None, \n",
    "    dpi=300, \n",
    "    interactive=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a 2D data array (e.g., DEM) over a latitude/longitude grid using Cartopy.\n",
    "\n",
    "    Parameters:\n",
    "        data_array (2D numpy array): The array to plot (e.g., elevation, temperature).\n",
    "        lat_grid (2D numpy array): Latitude grid corresponding to the data array.\n",
    "        lon_grid (2D numpy array): Longitude grid corresponding to the data array.\n",
    "        title (str): Title for the plot.\n",
    "        cmap (str): Colormap for the plot (default is 'jet').\n",
    "        unit_label (str): Label for the colorbar (default is 'Value').\n",
    "        save_fig (bool): If True, the figure may be saved based on interaction or filename.\n",
    "        filename (str): Name of the file to save the figure (e.g., 'plot.jpeg').\n",
    "        dpi (int): Resolution of the saved figure (default is 300).\n",
    "        interactive (bool): If True and save_fig is True, ask whether to save and prompt for path.\n",
    "    \"\"\"\n",
    "    # Determine min, max, and colorbar ticks\n",
    "    vmin = data_array.min()\n",
    "    vmax = data_array.max()\n",
    "    ticks = np.linspace(vmin, vmax, 10)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "    # Plot the data\n",
    "    mesh = ax.pcolormesh(\n",
    "        lon_grid,\n",
    "        lat_grid,\n",
    "        data_array,\n",
    "        shading='auto',\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        transform=ccrs.PlateCarree()\n",
    "    )\n",
    "\n",
    "    # Add gridlines\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {'size': 12}\n",
    "    gl.ylabel_style = {'size': 12}\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlocator = MultipleLocator(0.2)\n",
    "    gl.ylocator = MultipleLocator(0.2)\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(mesh, ax=ax, orientation='vertical', label=unit_label, shrink=0.7)\n",
    "    cbar.set_ticks(ticks)\n",
    "\n",
    "    # Add title\n",
    "    plt.title(title, fontsize=14)\n",
    "\n",
    "    # Handle save interaction\n",
    "    if save_fig:\n",
    "        if interactive and filename is None:\n",
    "            user_input = input(\"Do you want to save the plot as JPEG? (yes/no): \").strip().lower()\n",
    "            if user_input == \"yes\":\n",
    "                filename = input(\"Enter full path (including filename) to save the JPEG: \").strip()\n",
    "\n",
    "        if filename:\n",
    "            if not filename.lower().endswith(\".jpeg\"):\n",
    "                filename += \".jpeg\"\n",
    "            plt.savefig(filename, dpi=dpi, bbox_inches='tight')\n",
    "            print(f\"âœ… Figure saved as '{filename}'\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb8816-7165-4d26-9857-7ab0b588b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fft import fft2, ifft2, fftshift\n",
    "\n",
    "def compute_terrain_correction_fft(dem_array, dx=30, dy=30, rho=2670, G=6.67430e-11):\n",
    "    \"\"\"\n",
    "    Compute terrain correction using FFT-based method on a given DEM array.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dem_array : 2D numpy.ndarray\n",
    "        The digital elevation model (DEM) grid in meters.\n",
    "    dx : float, optional\n",
    "        Grid spacing in the x-direction (east-west) in meters. Default is 30.\n",
    "    dy : float, optional\n",
    "        Grid spacing in the y-direction (north-south) in meters. Default is 30.\n",
    "    rho : float, optional\n",
    "        Density of the crust in kg/mÂ³. Default is 2670.\n",
    "    G : float, optional\n",
    "        Gravitational constant in mÂ³/kg/sÂ². Default is 6.67430e-11.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    TC_mgal : 2D numpy.ndarray\n",
    "        Terrain correction in mGal.\n",
    "    \"\"\"\n",
    "    ny, nx = dem_array.shape\n",
    "    h_q = dem_array.astype(np.float64)\n",
    "\n",
    "    # Generate index grid\n",
    "    x = np.arange(-nx//2, nx//2, dtype=np.float64) * dx\n",
    "    y = np.arange(-ny//2, ny//2, dtype=np.float64) * dy\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Compute radial distance and kernel\n",
    "    r = np.sqrt(X**2 + Y**2)\n",
    "    r[r == 0] = np.inf  # Avoid division by zero\n",
    "    K = (1 / r**3) * dx * dy\n",
    "    K = fftshift(K)\n",
    "\n",
    "    # Perform FFT-based convolution\n",
    "    F_HQ2 = fft2(h_q**2)\n",
    "    F_HQ = fft2(h_q)\n",
    "    F_K = fft2(K)\n",
    "\n",
    "    I1 = ifft2(F_HQ2 * F_K).real\n",
    "    I2 = ifft2(fft2(np.ones_like(h_q)) * F_K).real\n",
    "    I3 = ifft2(F_HQ * F_K).real\n",
    "\n",
    "    # Terrain correction in mGal\n",
    "    TC = (G * rho / 2) * (I1 + h_q**2 * I2 - 2 * h_q * I3)\n",
    "    TC_mgal = TC * 1e5\n",
    "\n",
    "    return TC_mgal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bcf9ac-01f3-4cc2-b7d5-f20b918ee1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "def compute_terrain_correction_tiled(dem_array, tile_size=1024, pad=100, dx=30, dy=30, rho=2670, G=6.67430e-11):\n",
    "    \"\"\"\n",
    "    Compute terrain correction in tiles using FFT-based convolution to handle large DEM arrays.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dem_array : 2D numpy.ndarray\n",
    "        Digital elevation model (DEM) grid in meters.\n",
    "    tile_size : int, optional\n",
    "        Size of each square tile (e.g., 1024x1024). Default is 1024.\n",
    "    pad : int, optional\n",
    "        Padding size around each tile to minimize edge effects. Default is 100.\n",
    "    dx, dy : float\n",
    "        Grid spacing in x and y directions in meters. Defaults are 30 m.\n",
    "    rho : float, optional\n",
    "        Density of the crust in kg/mÂ³. Default is 2670.\n",
    "    G : float, optional\n",
    "        Gravitational constant in mÂ³/kg/sÂ². Default is 6.67430e-11.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    full_tc_mgal : 2D numpy.ndarray\n",
    "        Terrain correction in mGal, same shape as input DEM.\n",
    "    \"\"\"\n",
    "    ny, nx = dem_array.shape\n",
    "    full_tc_mgal = np.zeros_like(dem_array, dtype=np.float64)\n",
    "\n",
    "    def compute_tile(h_q):\n",
    "        ty, tx = h_q.shape\n",
    "        x = np.arange(-tx//2, tx//2) * dx\n",
    "        y = np.arange(-ty//2, ty//2) * dy\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        r = np.sqrt(X**2 + Y**2)\n",
    "        r[r == 0] = np.inf  # Avoid division by zero\n",
    "        K = (1 / r**3) * dx * dy\n",
    "\n",
    "        I1 = fftconvolve(h_q**2, K, mode='same')\n",
    "        I2 = fftconvolve(np.ones_like(h_q), K, mode='same')\n",
    "        I3 = fftconvolve(h_q, K, mode='same')\n",
    "\n",
    "        TC = (G * rho / 2) * (I1 + h_q**2 * I2 - 2 * h_q * I3)\n",
    "        return TC * 1e5  # Convert to mGal\n",
    "\n",
    "    for y_start in range(0, ny, tile_size):\n",
    "        for x_start in range(0, nx, tile_size):\n",
    "            y_end = min(y_start + tile_size, ny)\n",
    "            x_end = min(x_start + tile_size, nx)\n",
    "\n",
    "            # Determine padded bounds\n",
    "            yp_start = max(y_start - pad, 0)\n",
    "            yp_end = min(y_end + pad, ny)\n",
    "            xp_start = max(x_start - pad, 0)\n",
    "            xp_end = min(x_end + pad, nx)\n",
    "\n",
    "            # Extract padded tile\n",
    "            padded_tile = dem_array[yp_start:yp_end, xp_start:xp_end]\n",
    "\n",
    "            # Compute terrain correction on padded tile\n",
    "            tc_padded = compute_tile(padded_tile)\n",
    "\n",
    "            # Extract central (unpadded) region\n",
    "            y0 = y_start - yp_start\n",
    "            y1 = y0 + (y_end - y_start)\n",
    "            x0 = x_start - xp_start\n",
    "            x1 = x0 + (x_end - x_start)\n",
    "\n",
    "            full_tc_mgal[y_start:y_end, x_start:x_end] = tc_padded[y0:y1, x0:x1]\n",
    "\n",
    "    return full_tc_mgal\n",
    "\n",
    "# TC_mgal = compute_terrain_correction_tiled(dem_array, tile_size=1024, pad=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56fee38-0b4b-4f49-ad86-421942610d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fft import fft2, ifft2, fftshift\n",
    "\n",
    "def compute_spherical_stokes_convolution(\n",
    "    faye_anomaly_grid,\n",
    "    lat_grid,\n",
    "    lon_grid,\n",
    "    R=6371000,\n",
    "    arcsec_resolution=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the geoid undulation contribution using spherical Stokes convolution\n",
    "    via FFT based on a grid of Faye gravity anomalies.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    faye_anomaly_grid : 2D numpy.ndarray\n",
    "        Grid of Faye gravity anomalies (in mGal).\n",
    "    lat_grid : 2D numpy.ndarray\n",
    "        Latitude grid in decimal degrees (same shape as faye_anomaly_grid).\n",
    "    lon_grid : 2D numpy.ndarray\n",
    "        Longitude grid in decimal degrees (same shape as faye_anomaly_grid).\n",
    "    R : float, optional\n",
    "        Mean Earth radius in meters. Default is 6371000.\n",
    "    arcsec_resolution : float, optional\n",
    "        Grid resolution in arc-seconds. Default is 1 (i.e., 1 arc-second resolution).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    T_r_m2_per_s2 : 2D numpy.ndarray\n",
    "        Result of the Stokes convolution (in mÂ²/sÂ²).\n",
    "    \"\"\"\n",
    "    ny, nx = faye_anomaly_grid.shape\n",
    "\n",
    "    # Convert to radians\n",
    "    lat_rad = np.deg2rad(lat_grid).astype(np.float64)\n",
    "    lon_rad = np.deg2rad(lon_grid).astype(np.float64)\n",
    "\n",
    "    # Get center point\n",
    "    i_center = ny // 2\n",
    "    j_center = nx // 2\n",
    "    lat_p = lat_rad[i_center, j_center]\n",
    "    lon_p = lon_rad[i_center, j_center]\n",
    "\n",
    "    # Compute sinÂ²(Ïˆ/2)\n",
    "    sin_psi_by_2_squared = (\n",
    "        np.sin((lat_p - lat_rad) / 2)**2 +\n",
    "        np.cos(lat_p) * np.cos(lat_rad) * np.sin((lon_p - lon_rad) / 2)**2\n",
    "    )\n",
    "    sin_psi_by_2 = np.sqrt(sin_psi_by_2_squared)\n",
    "    sin_psi_by_2[i_center, j_center] = np.nan  # exclude center point\n",
    "\n",
    "    # Clamp and sanitize\n",
    "    sin_psi_by_2 = np.clip(sin_psi_by_2, 0, 1)\n",
    "    sin_psi_by_2 = np.nan_to_num(sin_psi_by_2, nan=1e-10)\n",
    "    psi = 2 * np.arcsin(sin_psi_by_2)\n",
    "\n",
    "    # Compute Stokes kernel S(Ïˆ)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        S_psi = (\n",
    "            (1 / sin_psi_by_2) -\n",
    "            6 * sin_psi_by_2 +\n",
    "            1 -\n",
    "            5 * np.cos(psi) -\n",
    "            3 * np.cos(psi) * np.log(np.maximum(sin_psi_by_2 + sin_psi_by_2_squared, 1e-10))\n",
    "        )\n",
    "    S_psi[i_center, j_center] = 0  # Set singular point to zero\n",
    "\n",
    "    # Compute area element correction (1 arcsec resolution)\n",
    "    dx = dy = (arcsec_resolution / 3600) * (np.pi / 180)  # arc-sec to radians\n",
    "    cos_phi = np.cos(lat_rad)\n",
    "    S_psi *= cos_phi * dx * dy\n",
    "\n",
    "    # Apply FFT-based convolution\n",
    "    F_S_psi = fft2(fftshift(S_psi))\n",
    "    F_faye = fft2(faye_anomaly_grid)\n",
    "    T_r = (R / (4 * np.pi)) * ifft2(F_faye * F_S_psi).real\n",
    "\n",
    "    # Convert result to mÂ²/sÂ²\n",
    "    T_r_m2_per_s2 = T_r * 1e-5\n",
    "\n",
    "    return T_r_m2_per_s2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c205b-a6c5-4c3d-ae69-13a05d77b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_normal_gravity_grid(lat_grid):\n",
    "    \"\"\"\n",
    "    Compute the normal gravity on the WGS84 ellipsoid for each point in a latitude grid.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lat_grid : 2D numpy.ndarray\n",
    "        Latitude grid in decimal degrees.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    g_normal_grid : 2D numpy.ndarray\n",
    "        Grid of normal gravity values (in m/sÂ²).\n",
    "    \"\"\"\n",
    "\n",
    "    # Ellipsoidal constants (WGS 84)\n",
    "    a = 6378137.0               # Semi-major axis (meters)\n",
    "    b = 6356752.3142            # Semi-minor axis (meters)\n",
    "    gamma_eq = 9.7803253359     # Normal gravity at equator (m/sÂ²)\n",
    "    gamma_pole = 9.8321849378   # Normal gravity at pole (m/sÂ²)\n",
    "\n",
    "    # Convert latitude to radians\n",
    "    lat_rad = np.radians(lat_grid)\n",
    "\n",
    "    # Compute normal gravity\n",
    "    g_normal_grid = (\n",
    "        (a * gamma_eq * np.cos(lat_rad)**2) +\n",
    "        (b * gamma_pole * np.sin(lat_rad)**2)\n",
    "    ) / (\n",
    "        np.sqrt((a**2 * np.cos(lat_rad)**2) +\n",
    "                (b**2 * np.sin(lat_rad)**2))\n",
    "    )\n",
    "\n",
    "    return g_normal_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa679d8-1afc-46d6-829e-9f58e3251d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fft import fft2, ifft2, fftshift\n",
    "\n",
    "def compute_indirect_effect_fft(dem_array, g_normal_grid, dx=30, dy=30, rho=2670, G=6.67430e-11):\n",
    "    \"\"\"\n",
    "    Compute the indirect effect for geoid modeling using FFT-based convolution.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dem_array : 2D numpy.ndarray\n",
    "        Digital Elevation Model (DEM) in meters.\n",
    "\n",
    "    g_normal_grid : 2D numpy.ndarray\n",
    "        Grid of normal gravity values (in m/sÂ²) for normalization.\n",
    "\n",
    "    dx : float, optional\n",
    "        Grid spacing in x-direction (meters). Default is 30.\n",
    "\n",
    "    dy : float, optional\n",
    "        Grid spacing in y-direction (meters). Default is 30.\n",
    "\n",
    "    rho : float, optional\n",
    "        Density of the crust in kg/mÂ³. Default is 2670.\n",
    "\n",
    "    G : float, optional\n",
    "        Gravitational constant in mÂ³ kgâ»Â¹ sâ»Â². Default is 6.67430e-11.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    N_indirect : 2D numpy.ndarray\n",
    "        Indirect effect in meters.\n",
    "    \"\"\"\n",
    "    # Get dimensions and convert to float64\n",
    "    ny, nx = dem_array.shape\n",
    "    h_q = dem_array.astype(np.float64)\n",
    "\n",
    "    # Generate distance grid\n",
    "    x = np.arange(-nx // 2, nx // 2, dtype=np.float64) * dx\n",
    "    y = np.arange(-ny // 2, ny // 2, dtype=np.float64) * dy\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Compute radial distance r\n",
    "    r = np.sqrt(X**2 + Y**2)\n",
    "    r[r == 0] = np.inf  # Avoid division by zero\n",
    "\n",
    "    # Compute kernel (1/r^3) and account for area\n",
    "    K = (1 / r**3) * dx * dy\n",
    "    K = fftshift(K)\n",
    "\n",
    "    # Compute FFTs\n",
    "    F_HQ3 = fft2(h_q**3)\n",
    "    F_1 = fft2(np.ones_like(h_q))\n",
    "    F_K = fft2(K)\n",
    "\n",
    "    # FFT-based convolution terms\n",
    "    Term1 = ifft2(F_HQ3 * F_K).real\n",
    "    Term2 = ifft2(F_1 * F_K).real\n",
    "\n",
    "    # Compute indirect effect\n",
    "    N_indirect = (-G * rho) * (np.pi * h_q**2 + (1 / 6) * (Term1 - h_q**3 * Term2))\n",
    "\n",
    "    # Normalize by normal gravity\n",
    "    N_indirect /= g_normal_grid\n",
    "\n",
    "    return N_indirect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06907967-b85b-4f72-8f50-fe37c9bada22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "def compute_indirect_effect_tiled(dem_array, g_normal_grid, tile_size=1024, pad=100,\n",
    "                                   dx=30, dy=30, rho=2670, G=6.67430e-11):\n",
    "    \"\"\"\n",
    "    Compute the indirect effect for geoid modeling using a tiled FFT-based convolution approach.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dem_array : 2D numpy.ndarray\n",
    "        Digital Elevation Model (DEM) in meters.\n",
    "    g_normal_grid : 2D numpy.ndarray\n",
    "        Normal gravity grid (in m/sÂ²) for normalization.\n",
    "    tile_size : int\n",
    "        Size of processing tiles (e.g., 1024).\n",
    "    pad : int\n",
    "        Padding added to each tile to minimize edge effects.\n",
    "    dx, dy : float\n",
    "        Grid spacing in meters.\n",
    "    rho : float\n",
    "        Density in kg/mÂ³. Default 2670.\n",
    "    G : float\n",
    "        Gravitational constant in mÂ³/kg/sÂ². Default 6.67430e-11.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    full_indirect : 2D numpy.ndarray\n",
    "        Indirect effect in meters.\n",
    "    \"\"\"\n",
    "    ny, nx = dem_array.shape\n",
    "    full_indirect = np.zeros_like(dem_array, dtype=np.float64)\n",
    "\n",
    "    def compute_tile(h_q_tile, g_tile):\n",
    "        ty, tx = h_q_tile.shape\n",
    "        x = np.arange(-tx // 2, tx // 2) * dx\n",
    "        y = np.arange(-ty // 2, ty // 2) * dy\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "\n",
    "        r = np.sqrt(X**2 + Y**2)\n",
    "        r[r == 0] = np.inf\n",
    "        K = (1 / r**3) * dx * dy\n",
    "\n",
    "        Term1 = fftconvolve(h_q_tile**3, K, mode='same')\n",
    "        Term2 = fftconvolve(np.ones_like(h_q_tile), K, mode='same')\n",
    "\n",
    "        N_indirect = (-G * rho) * (np.pi * h_q_tile**2 + (1 / 6) * (Term1 - h_q_tile**3 * Term2))\n",
    "        N_indirect /= g_tile\n",
    "        return N_indirect\n",
    "\n",
    "    for y_start in range(0, ny, tile_size):\n",
    "        for x_start in range(0, nx, tile_size):\n",
    "            y_end = min(y_start + tile_size, ny)\n",
    "            x_end = min(x_start + tile_size, nx)\n",
    "\n",
    "            # Padded region\n",
    "            yp_start = max(y_start - pad, 0)\n",
    "            yp_end = min(y_end + pad, ny)\n",
    "            xp_start = max(x_start - pad, 0)\n",
    "            xp_end = min(x_end + pad, nx)\n",
    "\n",
    "            h_tile_padded = dem_array[yp_start:yp_end, xp_start:xp_end]\n",
    "            g_tile_padded = g_normal_grid[yp_start:yp_end, xp_start:xp_end]\n",
    "\n",
    "            n_tile = compute_tile(h_tile_padded, g_tile_padded)\n",
    "\n",
    "            # Extract central tile from padded output\n",
    "            y0 = y_start - yp_start\n",
    "            y1 = y0 + (y_end - y_start)\n",
    "            x0 = x_start - xp_start\n",
    "            x1 = x0 + (x_end - x_start)\n",
    "\n",
    "            full_indirect[y_start:y_end, x_start:x_end] = n_tile[y0:y1, x0:x1]\n",
    "\n",
    "    return full_indirect\n",
    "\n",
    "# N_indirect = compute_indirect_effect_tiled(dem_array, g_normal_grid, tile_size=1024, pad=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342847c-ee9e-49f8-bd83-0d27340030a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_gsvs17_colorado(filepath=None):\n",
    "    \"\"\"\n",
    "    Load GSVS17 (Colorado, 2017) Geoid Slope Validation Survey data.\n",
    "\n",
    "    This survey evaluates geoid accuracy in a rugged, high elevation, gravimetrically \n",
    "    and topographically complex region.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str, optional\n",
    "        Path to the GSVS17 Excel file. If not provided, user will be prompted to input it.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing Latitude, Longitude, Ellipsoid Height, Orthometric Height, and Geometric Geoid.\n",
    "    \"\"\"\n",
    "    if filepath is None:\n",
    "        filepath = input(\"Enter file path for GSVS17 (Colorado) Excel file: \")\n",
    "\n",
    "    df = pd.read_excel(filepath, usecols=\"J:M\")\n",
    "    df.columns = ['Latitude', 'Longitude', 'Ellipsoid_Height', 'Orthometric_Height']\n",
    "    df['Longitude'] = df['Longitude'].apply(lambda x: x - 360 if x > 180 else x)\n",
    "    df['Geometric_Geoid'] = df['Ellipsoid_Height'] - df['Orthometric_Height']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb4de5-2941-4284-bf77-d2cd56740a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gsvs14_iowa(filepath=None):\n",
    "    \"\"\"\n",
    "    Load GSVS14 (Iowa, 2014) Geoid Slope Validation Survey data.\n",
    "\n",
    "    This survey evaluates geoid accuracy in a flat, high elevation, and gravimetrically complex region.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str, optional\n",
    "        Path to the GSVS14 Excel file. If not provided, user will be prompted to input it.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing Latitude, Longitude, Ellipsoid Height, Orthometric Height, and Geometric Geoid.\n",
    "    \"\"\"\n",
    "    if filepath is None:\n",
    "        filepath = input(\"Enter file path for GSVS14 (Iowa) Excel file: \")\n",
    "\n",
    "    df = pd.read_excel(filepath, usecols=\"D,H,L,M\")\n",
    "    df.columns = ['Latitude', 'Longitude', 'Ellipsoid_Height', 'Orthometric_Height']\n",
    "    df['Longitude'] = df['Longitude'].apply(lambda lon: lon - 360 if lon > 180 else lon)\n",
    "    df['Geometric_Geoid'] = df['Ellipsoid_Height'] - df['Orthometric_Height']\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e505cf4-36ea-4b22-9226-832cb8bc2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gsvs11_texas(filepath=None):\n",
    "    \"\"\"\n",
    "    Load GSVS11 (Texas, 2011) Geoid Slope Validation Survey data.\n",
    "\n",
    "    This survey evaluates geoid accuracy in a flat and gravimetrically uncomplicated region.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str, optional\n",
    "        Path to the GSVS11 Excel file. If not provided, user will be prompted to input it.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing Latitude, Longitude, Ellipsoid Height, Orthometric Height, and Geometric Geoid.\n",
    "    \"\"\"\n",
    "    if filepath is None:\n",
    "        filepath = input(\"Enter file path for GSVS11 (Texas) Excel file: \")\n",
    "\n",
    "    df = pd.read_excel(filepath, usecols=\"I,M,Q,R\")\n",
    "    df.columns = ['Latitude', 'Longitude', 'Ellipsoid_Height', 'Orthometric_Height']\n",
    "    df['Longitude'] = -df['Longitude'].abs()\n",
    "    df['Geometric_Geoid'] = df['Ellipsoid_Height'] - df['Orthometric_Height']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57cdd0-8d59-483a-8998-6ea8a6193aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
